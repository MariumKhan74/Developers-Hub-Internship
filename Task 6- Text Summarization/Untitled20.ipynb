{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb0dfe1-745e-42e5-a4aa-e703e9901935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "val_df = pd.read_csv('validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319473ac-4ab2-4eee-871f-9627bd1e549d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
       "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
       "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
       "      <td>A drunk driver who killed a young woman in a h...</td>\n",
       "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
       "      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n",
       "      <td>Nina dos Santos says Europe must be ready to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n",
       "      <td>Fleetwood are the only team still to have a 10...</td>\n",
       "      <td>Fleetwood top of League One after 2-0 win at S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n",
       "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n",
       "2  00027e965c8264c35cc1bc55556db388da82b07f   \n",
       "3  0002c17436637c4fe1837c935c04de47adb18e9a   \n",
       "4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n",
       "\n",
       "                                             article  \\\n",
       "0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
       "1  (CNN) -- Ralph Mata was an internal affairs li...   \n",
       "2  A drunk driver who killed a young woman in a h...   \n",
       "3  (CNN) -- With a breezy sweep of his pen Presid...   \n",
       "4  Fleetwood are the only team still to have a 10...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Bishop John Folda, of North Dakota, is taking ...  \n",
       "1  Criminal complaint: Cop used his role to help ...  \n",
       "2  Craig Eccleston-Todd, 27, had drunk at least t...  \n",
       "3  Nina dos Santos says Europe must be ready to a...  \n",
       "4  Fleetwood top of League One after 2-0 win at S...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58719656-1895-43fb-b6c3-13e31230977f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92c514c913c0bdfe25341af9fd72b29db544099b</td>\n",
       "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
       "      <td>Experts question if  packed out planes are put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003841c7dc0e7c5b1a248f9cd536d727f27a45a</td>\n",
       "      <td>A drunk teenage boy had to be rescued by secur...</td>\n",
       "      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91b7d2311527f5c2b63a65ca98d21d9c92485149</td>\n",
       "      <td>Dougie Freedman is on the verge of agreeing a ...</td>\n",
       "      <td>Nottingham Forest are close to extending Dougi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caabf9cbdf96eb1410295a673e953d304391bfbb</td>\n",
       "      <td>Liverpool target Neto is also wanted by PSG an...</td>\n",
       "      <td>Fiorentina goalkeeper Neto has been linked wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3da746a7d9afcaa659088c8366ef6347fe6b53ea</td>\n",
       "      <td>Bruce Jenner will break his silence in a two-h...</td>\n",
       "      <td>Tell-all interview with the reality TV star, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
       "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
       "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
       "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
       "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
       "\n",
       "                                             article  \\\n",
       "0  Ever noticed how plane seats appear to be gett...   \n",
       "1  A drunk teenage boy had to be rescued by secur...   \n",
       "2  Dougie Freedman is on the verge of agreeing a ...   \n",
       "3  Liverpool target Neto is also wanted by PSG an...   \n",
       "4  Bruce Jenner will break his silence in a two-h...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Experts question if  packed out planes are put...  \n",
       "1  Drunk teenage boy climbed into lion enclosure ...  \n",
       "2  Nottingham Forest are close to extending Dougi...  \n",
       "3  Fiorentina goalkeeper Neto has been linked wit...  \n",
       "4  Tell-all interview with the reality TV star, 6...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c532069-fd78-49be-9fe8-19bf3cfd3e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61df4979ac5fcc2b71be46ed6fe5a46ce7f071c3</td>\n",
       "      <td>Sally Forrest, an actress-dancer who graced th...</td>\n",
       "      <td>Sally Forrest, an actress-dancer who graced th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21c0bd69b7e7df285c3d1b1cf56d4da925980a68</td>\n",
       "      <td>A middle-school teacher in China has inked hun...</td>\n",
       "      <td>Works include pictures of Presidential Palace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56f340189cd128194b2e7cb8c26bb900e3a848b4</td>\n",
       "      <td>A man convicted of killing the father and sist...</td>\n",
       "      <td>Iftekhar Murtaza, 29, was convicted a year ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a665151b89a53e5a08a389df8334f4106494c2</td>\n",
       "      <td>Avid rugby fan Prince Harry could barely watch...</td>\n",
       "      <td>Prince Harry in attendance for England's crunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9f6fbd3c497c4d28879bebebea220884f03eb41a</td>\n",
       "      <td>A Triple M Radio producer has been inundated w...</td>\n",
       "      <td>Nick Slater's colleagues uploaded a picture to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  61df4979ac5fcc2b71be46ed6fe5a46ce7f071c3   \n",
       "1  21c0bd69b7e7df285c3d1b1cf56d4da925980a68   \n",
       "2  56f340189cd128194b2e7cb8c26bb900e3a848b4   \n",
       "3  00a665151b89a53e5a08a389df8334f4106494c2   \n",
       "4  9f6fbd3c497c4d28879bebebea220884f03eb41a   \n",
       "\n",
       "                                             article  \\\n",
       "0  Sally Forrest, an actress-dancer who graced th...   \n",
       "1  A middle-school teacher in China has inked hun...   \n",
       "2  A man convicted of killing the father and sist...   \n",
       "3  Avid rugby fan Prince Harry could barely watch...   \n",
       "4  A Triple M Radio producer has been inundated w...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Sally Forrest, an actress-dancer who graced th...  \n",
       "1  Works include pictures of Presidential Palace ...  \n",
       "2  Iftekhar Murtaza, 29, was convicted a year ago...  \n",
       "3  Prince Harry in attendance for England's crunc...  \n",
       "4  Nick Slater's colleagues uploaded a picture to...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199ad254-5fb3-4567-b98e-3b911707496d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "article       0\n",
       "highlights    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1400ddb-9cf9-4aef-8d5e-24ddeeb01e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         id  \\\n",
      "0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n",
      "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n",
      "2  00027e965c8264c35cc1bc55556db388da82b07f   \n",
      "3  0002c17436637c4fe1837c935c04de47adb18e9a   \n",
      "4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n",
      "\n",
      "                                             article  \\\n",
      "0  by . associated press . published: . 14:11 est...   \n",
      "1  (cnn) -- ralph mata was an internal affairs li...   \n",
      "2  a drunk driver who killed a young woman in a h...   \n",
      "3  (cnn) -- with a breezy sweep of his pen presid...   \n",
      "4  fleetwood are the only team still to have a 10...   \n",
      "\n",
      "                                          highlights  \n",
      "0  bishop john folda, of north dakota, is taking ...  \n",
      "1  criminal complaint: cop used his role to help ...  \n",
      "2  craig eccleston-todd, 27, had drunk at least t...  \n",
      "3  nina dos santos says europe must be ready to a...  \n",
      "4  fleetwood top of league one after 2-0 win at s...  \n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ').strip()\n",
    "    return text\n",
    "\n",
    "# Clean the 'article' and 'highlights' columns\n",
    "train_df['article'] = train_df['article'].apply(clean_text)\n",
    "train_df['highlights'] = train_df['highlights'].apply(clean_text)\n",
    "\n",
    "test_df['article'] = test_df['article'].apply(clean_text)\n",
    "test_df['highlights'] = test_df['highlights'].apply(clean_text)\n",
    "val_df['article'] = val_df['article'].apply(clean_text)\n",
    "val_df['highlights'] = val_df['highlights'].apply(clean_text)\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376a0c7c-5304-409e-a03a-8ffb13bf9630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mariu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mariu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mariu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary resources from NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    preprocessed_sentences = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Remove punctuation using regex\n",
    "        sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "        \n",
    "        # Tokenize the sentence into words\n",
    "        words = word_tokenize(sentence)\n",
    "        \n",
    "        # Remove stopwords and lemmatize words\n",
    "        filtered_words = [\n",
    "            lemmatizer.lemmatize(word.lower())  # Lemmatize and convert to lowercase\n",
    "            for word in words if word.lower() not in stop_words and word.isalnum()\n",
    "        ]\n",
    "        \n",
    "        # Rebuild the sentence from the filtered words\n",
    "        preprocessed_sentence = ' '.join(filtered_words)\n",
    "        preprocessed_sentences.append(preprocessed_sentence)\n",
    "    \n",
    "    # Join the sentences back into a full text\n",
    "    preprocessed_text = ' '.join(preprocessed_sentences)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce3af16-dea8-4302-a35f-302de45a6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def extractive_summary(text, top_n=3):\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Create the TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    # Calculate cosine similarity matrix\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    # Sum the similarity scores for each sentence\n",
    "    sentence_scores = cosine_sim.sum(axis=1)\n",
    "    \n",
    "    # Get the indices of the top_n sentences with highest scores\n",
    "    ranked_sentences = sentence_scores.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # Extract the top N sentences\n",
    "    summary = ' '.join([sentences[i] for i in ranked_sentences])\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e0d80f-24fe-44e0-9c0b-26ee92993737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pre-trained T5 model for summarization\n",
    "summarizer = pipeline('summarization', model='t5-small')\n",
    "\n",
    "def abstractive_summary(text):\n",
    "    summary = summarizer(text, max_length=150, min_length=50, do_sample=False)\n",
    "    return summary[0]['summary_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f8e6b38-055d-4637-9d78-0a07926273f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_1984\\3706417911.py:66: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\mariu\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1, training_loss=16.43187141418457, metrics={'train_runtime': 14.5338, 'train_samples_per_second': 0.138, 'train_steps_per_second': 0.069, 'total_flos': 270683602944.0, 'train_loss': 16.43187141418457, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"article\": \"The Apollo missions landed the first humans on the Moon. The program ran from 1961 to 1972 and achieved six successful lunar landings.\",\n",
    "        \"summary\": \"The Apollo program landed humans on the Moon between 1961 and 1972.\"\n",
    "    },\n",
    "    {\n",
    "        \"article\": \"The Eiffel Tower is a wrought-iron lattice tower in Paris, France. It is one of the most recognizable structures in the world.\",\n",
    "        \"summary\": \"The Eiffel Tower is a famous landmark in Paris.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Prepare dataset\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_input_length=512, max_output_length=128):\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "        for item in data:\n",
    "            input_enc = tokenizer(\n",
    "                \"summarize: \" + item[\"article\"],\n",
    "                max_length=max_input_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            label_enc = tokenizer(\n",
    "                item[\"summary\"],\n",
    "                max_length=max_output_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            self.inputs.append(input_enc.input_ids.squeeze())\n",
    "            self.labels.append(label_enc.input_ids.squeeze())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.inputs[idx],\n",
    "            \"attention_mask\": self.inputs[idx].ne(tokenizer.pad_token_id),\n",
    "            \"labels\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "train_dataset = SummaryDataset(data, tokenizer)\n",
    "\n",
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_strategy=\"no\",\n",
    "    logging_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fedc1a3-72ee-4e51-8fce-3cc450a2af16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Great wall of China stretches over 13,000 miles.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The Great Wall of China is a historic structure built to protect states from invasions. It stretches over 13,000 miles.\"\n",
    "\n",
    "# Tokenize input and generate summary\n",
    "input_ids = tokenizer.encode(\"summarize: \" + input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Generate the summary\n",
    "summary_ids = model.generate(input_ids, max_length=150, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Decode and print the summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01fc047c-c8ee-42d7-9eac-ce5995c249d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./t5-summary-model\\\\tokenizer_config.json',\n",
       " './t5-summary-model\\\\special_tokens_map.json',\n",
       " './t5-summary-model\\\\spiece.model',\n",
       " './t5-summary-model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./t5-summary-model\")\n",
    "tokenizer.save_pretrained(\"./t5-summary-model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
